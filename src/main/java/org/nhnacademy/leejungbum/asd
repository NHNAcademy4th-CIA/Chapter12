질문 1:

1부터 10까지의 숫자를 기록하는 스레드를 나타내는 Thread 의 완전한 하위 클래스를 작성합니다. 그런 다음 해당 클래스에 속하는 스레드를 생성하고 시작하는 코드를 작성합니다.

답변:

스레드를 정의하는 클래스:

공개 클래스 CountingThread는 Thread {를 확장합니다.
   공개 정적 실행() {
      for (int i = 1; i <= 10; i++)
         System.out.println(i);
   }
}
CountingThread 유형의 객체를 생성 하고 스레드를 시작하는 코드:

카운팅스레드 카운터; // 스레드를 나타내는 변수를 선언합니다.
카운터 = 새로운 CountingThread(); // 스레드 객체를 생성합니다.
counter.start(); // 스레드 실행을 시작합니다.
(새 스레드를 생성하고 하나의 명령문으로 시작할 수 있습니다.

새로운 CountingThread().start();
new 연산자 의 우선순위로 인해 이는 (new CountingThread()).start() 와 동일하며 그 효과는 CountingThread 유형의 새 객체를 생성한 다음 해당 객체에서 start() 메서드를 호출하는 것입니다.)

질문 2:

thrd 가 Thread 유형의 객체라고 가정합니다 . thrd.start() 호출과 thrd.run() 호출 의 차이점을 설명하세요 .

답변:

thrd.start() 를 호출하면 새 제어 스레드가 생성되고 그렇게 한 후 즉시 반환됩니다. 그런 다음 스레드의 run() 메서드가 새 제어 스레드에서 호출됩니다. run() 메서드 의 코드는 thrd.start() 호출 다음에 나오는 코드와 동시에 병렬로 실행됩니다 .

thrd.run() 문은 일반적인 방법으로 run 메서드를 호출합니다. run() 메서드는 run() 을 호출한 메서드와 동일한 제어 스레드에서 실행됩니다 . run() 메서드가 반환된 후에만 thrd.run() 뒤에 오는 코드가 실행됩니다.

질문 3:

경쟁 조건 이란 무엇입니까 ?

답변:

경쟁 조건은 다중 스레드 프로그램에서 발생할 수 있는 문제입니다. 스레드가 한 작업이 이전 작업의 결과에 따라 달라질 수 있는 일련의 작업을 수행한다고 가정합니다. 경쟁 조건은 첫 번째 스레드가 시퀀스를 완료하기 전에 다른 스레드가 이전 작업의 결과를 변경하거나 무효화할 수 있는 경우 발생합니다. 예를 들어, 단순 할당문 count = count+1 에는 일련의 단계로 실행되기 때문에 경쟁 조건이 있습니다. count 의 이전 값을 읽고 해당 값에 하나를 더한 다음 새 값을 count 에 다시 저장합니다 . 다른 스레드가 count 에 저장된 값을 증가시키는 것이 가능하면 경쟁 조건이 발생합니다.첫 번째 스레드가 이전 값을 읽는 시간과 새 값을 저장하는 시간 사이입니다. 이 경우 경쟁 조건으로 인해 count 값이 잘못될 수 있습니다 . count가 2로 증가해야 하는데 1로 증가할 수 있습니다. 또 다른 예는 if 문에서 발생합니다.

if ( !list.isEmpty() )
    return list.removeFirst();
첫 번째 스레드가 목록이 비어 있는지 테스트하는 시간과 첫 번째 스레드가 목록에서 요소를 제거하려고 시도하는 시간 사이에 다른 스레드가 목록을 비울 수 있는 경우 경쟁 조건이 있습니다. 이 경우 첫 번째 스레드가 빈 목록에서 항목을 제거하려고 하면 경쟁 조건으로 인해 예외가 발생할 수 있습니다.

질문 4:

동기화는 경쟁 조건을 어떻게 방지하며, 동기화는 상호 배제 만을 제공한다는 것은 무엇을 의미합니까 ?

답변:

동기화를 사용하면 스레드가 다른 스레드의 간섭 없이 일련의 작업을 완료할 수 있습니다. 두 스레드는 동시에 동일한 개체에서 동기화될 수 없습니다. 한 스레드가 동기화된 코드 블록을 실행하는 동안 다른 스레드가 동일한 코드 블록이나 동일한 개체에서 동기화된 다른 코드 블록을 실행하는 것은 불가능합니다. 예를 들어 스레드가 실행되는 경우

동기화(목록) {
   if ( !list.isEmpty() )
      return list.removeFirst();
}
그런 다음 목록을 조작하는 모든 코드가 적절하게 동기화되었다고 가정하면 첫 번째 스레드가 목록이 비어 있는지 테스트하는 시간과 첫 번째 요소를 제거하는 시간 사이에 다른 스레드가 목록을 비울 수 없다는 것을 확신할 수 있습니다. 목록에서.

동기화는 동일한 개체에서 동기화되는 다른 스레드로부터만 스레드를 보호하므로 상호 배제 만 제공합니다 . 예제에서 코드는 목록을 조작하는 모든 코드 세그먼트가 동기화된 경우에만 목록 에 독점적으로 액세스할 수 있습니다 . 동기화 없이 list.clear() 문을 실행하는 스레드에 대한 보호 기능은 없습니다 .

질문 5:

프로그램이 실행하는 데 4초가 걸리는 단일 스레드를 사용한다고 가정합니다. 이제 프로그램이 두 개의 스레드를 생성하고 두 스레드 간에 동일한 작업을 나눈다고 가정합니다. 두 개의 스레드를 사용하는 프로그램의 예상 실행 시간에 대해 무엇을 말할 수 있습니까?

답변:

실행 시간은 프로그램이 둘 이상의 프로세서가 있는 컴퓨터에서 실행되는지 여부에 따라 달라집니다. 그렇다면 두 프로세서 각각이 4초 분량의 작업을 절반씩 수행할 수 있으므로 실행 시간은 2초 정도로 짧을 수 있습니다. 그러나 컴퓨터에 프로세서가 하나만 있는 경우 모든 작업을 단일 프로세서에서 수행해야 하므로 2스레드 프로그램은 여전히 ​​4초가 걸립니다. (멀티프로세서 컴퓨터에서도 작업이 두 스레드에 균등하게 분배되지 않으면 2초 이상 걸릴 수 있습니다.)

질문 6:

ArrayBlockingQueue 란 무엇 이며 생산자/소비자 문제를 어떻게 해결합니까?

답변:

ArrayBlockingQueue는 항목 추가 및 제거 작업 이 차단될 수 있는 대기열입니다. 대기열이 가득 차면 항목 추가가 차단됩니다. 대기열이 비어 있으면 항목을 제거하면 차단됩니다. (또한 대기열의 작업은 다중 스레드 프로그램에서 사용할 수 있도록 적절하게 동기화됩니다.)

생산자/소비자 문제는 한 스레드 그룹에서 생성된 항목을 해당 항목을 소비하는 두 번째 스레드 그룹으로 안전하고 효율적으로 가져오는 문제입니다. 항목이 차단 대기열을 통해 전송되는 경우 두 번째 그룹의 스레드는 소비할 수 있는 항목이 없을 때 차단되고, 첫 번째 그룹의 스레드는 소비할 수 있는 것보다 더 빠르게 항목을 생성하는 경우 차단됩니다. (게다가 동기화를 통해 항목이 두 번 손실되거나 소모되지 않도록 보장합니다.)

소비 스레드만 차단해야 하는 애플리케이션에서는 용량이 무제한인 LinkedBlockingQueue 를 사용할 수 있습니다.

질문 7:

스레드 풀이 란 무엇입니까 ?

답변:

스레드 풀은 각 작업을 실행하기 위해 새 스레드를 만드는 대신 많은 수의 작업을 수행해야 할 때 사용됩니다. 스레드 풀은 작업을 수행하는 데 사용할 수 있는 상대적으로 작은 스레드 모음입니다. 작업이 사용 가능해지면 작업에 대한 새 스레드를 생성하는 대신 작업이 풀의 스레드 중 하나에 할당됩니다. 작업이 완료되면 스레드는 더 많은 작업을 할당할 수 있도록 풀로 다시 이동합니다.

일반적으로 작업은 사용 가능해지면 대기열에 배치됩니다. 풀의 각 스레드는 대기열에서 작업을 반복적으로 가져와 실행하는 무한 루프에서 실행됩니다. (블로킹 큐는 이 애플리케이션에 적합합니다.)

질문 8:

네트워크 서버 프로그램은 다중 스레드인 경우가 많습니다. 이것이 무엇을 의미하며 왜 그것이 사실인지 설명하십시오.

답변:

다중 스레드 서버는 스레드를 사용하여 허용되는 클라이언트 연결을 처리합니다. 서버 프로그램은 일반적으로 많은 클라이언트의 연결 요청을 처리하도록 설계되었습니다. 연결 요청을 수락하고 처리하는 무한 루프에서 실행됩니다. 처리하는 데 상당한 시간이 걸릴 경우 현재 클라이언트가 처리되는 동안 다른 클라이언트를 기다리게 하는 것은 좋지 않습니다. 해결책은 서버가 각 클라이언트 연결을 처리할 새 스레드를 만들거나 클라이언트 연결을 처리할 수 있는 스레드의 스레드 풀을 사용하는 것입니다. 첫 번째 클라이언트가 서비스되는 동안에도 서버는 계속해서 더 많은 클라이언트 연결을 허용할 수 있습니다.

질문 9:

다중 스레드 네트워크 서버 프로그램이 종종 사용 가능한 프로세서 수보다 몇 배 더 많은 스레드를 사용하는 이유는 무엇입니까?

답변:

네트워크 작업이 차단 될 수 있습니다 . 이는 클라이언트와의 통신을 처리하는 스레드가 대부분의 시간을 휴면 상태로 보내는 경우가 많다는 것을 의미합니다. 모든 프로세서를 계속 사용하려면 활성 스레드 수가 프로세서 수와 비슷해야 합니다. 특정 시점에 활성 스레드 수가 총 스레드 수의 일부에 불과한 경우 총 스레드 수는 프로세서 수의 몇 배가 되어야 합니다.

질문 10:

하위 섹션 12.1.3 의 ThreadSafeCounter 예제를 고려해보세요 .

공개 클래스 ThreadSafeCounter {

   개인 정수 개수 = 0; // 카운터의 값입니다.

   동기화된 공개 무효 증가() {
      개수 = 개수 + 1;
   }

   동기화된 공개 int getValue() {
      반환 횟수;
   }

}
increment () 메소드는 메소드 호출자가 다른 스레드의 방해 없이 "카운트 값 가져오기", "값에 1 추가", "카운트에 새 값 저장" 작업의 세 단계를 완료할 수 있도록 동기화됩니다. 그러나 getValue()는 하나의 간단한 단계로 구성됩니다. getValue()가 동기화되는 이유는 무엇입니까 ? (이것은 깊고 까다로운 질문입니다.)

답변:

getValue () 메소드는 하위 섹션 12.1.4 에서 논의된 로컬 데이터의 캐싱으로 인해 동기화되어야 합니다 . getValue()가 동기화되지 않은 경우 getValue() 를 호출하는 스레드가 최신 값이 아닌 이전에 캐시된 count 값을 볼 수 있습니다. 동기화를 통해 최신 count 값이 표시됩니다. count가 휘발성 변수 로 선언된 경우 getValue()를 동기화할 필요가 없습니다. 그러나 경쟁 조건을 방지하려면 increment()를 동기화해야 합니다.